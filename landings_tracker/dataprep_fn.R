dataprep_fn <- function(comp_dat_raw_load, gdp_defl, datpull_date) {

# This script pulls data and formats the dataframe for use in the app #
library(dplyr)
library(data.table)
library(reshape2)
library(lubridate)
library(edcdataprep)
library(tidyr)
  
if( !is.element('progress', .packages(all.available = TRUE)) ) {
    install.packages('progress')
  }
  library(progress)

source("helperfns.R")
source("cumul_prep_fn.R")

# There are three types of data aggregations:
# 1. daily vessel (raw data) - day_
# 2. weekly/monthly vessel - week_ month_ both_
# 3. weekly/monthly statistics (mean, median, total) - summ_

# Data Load requirements based off of data pull date.#############
# We do not want to include data from a week that has not completed or a month that is not over
# We include a 3 day lag here
# datpull_date is generated by the datapull.R file
# Week must be less than 'week_datpull_date'
week_datpull_date <- as.numeric(format((datpull_date-3), "%V"))
# Month must be less than 'month_datpull_date'
month_datpull_date <- month(datpull_date-3)
# Set completeness cutoff at 14 days prior to datpull date ###############
# All data after this date will be shown with uncertainty
# For Washington apply 28 day cutoff.
completeness_cutoff <- datpull_date - 14
month_cutoff <- month(completeness_cutoff) - 1
# cutoffs for washington
wk4_completeness <- datpull_date - 28
wk4_month <- month(wk4_completeness) - 1

# Load data from data_pull.R ####
day_raw <- comp_dat_raw_load %>%
  select(-TICKET_SOURCE_CODE) %>%
  filter(LANDING_YEAR > 2014) %>%
  subset(!is.na(VESSEL_NUM)) %>%
  # reaggregate, after removing the fish ticket source code column)
  group_by(VESSEL_NUM, DEALER_NUM, LANDING_MONTH, LANDING_DATE, SPECIES_GROUP, LANDING_YEAR, AGENCY_CODE) %>%
  summarise_all(sum)

# Create an "all non-whiting groundfish" category
grndfsh_list <- c('NEARSHORE GROUNDFISH',
    'OFFSHORE GROUNDFISH',
    'NON-WHITING GROUNDFISH NON-IFQ',
    'NON-WHITING GROUNDFISH IFQ',
    'MIDWATER')

day_raw_grnd <- filter(day_raw, SPECIES_GROUP %in% grndfsh_list) %>%
    mutate(SPECIES_GROUP = 'ALL NON-WHITING') %>%
    group_by(LANDING_YEAR, LANDING_MONTH, LANDING_DATE, AGENCY_CODE, VESSEL_NUM, DEALER_NUM, SPECIES_GROUP) %>%
    summarize(
        ROUND_WEIGHT_MTONS = sum(ROUND_WEIGHT_MTONS),
        EXVESSEL_REVENUE = sum(EXVESSEL_REVENUE), .groups = 'drop') %>%
    data.frame()

# combine fishery-level daily data with all groundfish daily data
day_raw_all <- rbind(day_raw, day_raw_grnd) %>%
    data.frame()

# Remove outliers and add week and do inflation adjustment
day_raw_all_fmt <- day_raw_all %>%
    subset(EXVESSEL_REVENUE/(ROUND_WEIGHT_MTONS*2204.62) < 150) %>%
    mutate(WEEKOFYEAR = as.numeric(format(LANDING_DATE, "%V"))) %>%
    mutate(WEEKOFYEAR = ifelse(WEEKOFYEAR == 53, 52, WEEKOFYEAR)) %>%
    #select(-LANDING_DATE) %>%
    reshape2::melt(c('VESSEL_NUM','DEALER_NUM','SPECIES_GROUP','LANDING_YEAR','WEEKOFYEAR', 'LANDING_MONTH', 'AGENCY_CODE', 'LANDING_DATE')) %>%
    rename(
      Metric = variable,
      Value = value) %>%
    # Deflator is being used here #
    left_join(gdp_defl, by = 'LANDING_YEAR') %>%
    mutate(Value = case_when(Metric == 'EXVESSEL_REVENUE' ~ Value/DEFL,
        T ~ Value)) %>%
    select(-DEFL)

# day_raw_full for COVID analysis (no fisheries removed)

day_raw_full_keep_all_fisheries <- mutate(day_raw_all_fmt, AGENCY_CODE = 'All') %>%
  rbind(day_raw_all_fmt) %>%
  # recode agency_code->state, species_group->species
  mutate(
    State = convert_state(AGENCY_CODE),
    Species = convert_sp(SPECIES_GROUP),
    Year = as.character(LANDING_YEAR))

#saveRDS(day_raw_full_keep_all_fisheries, "day_raw_full_keep_all_fisheries.RDS")
saveRDS(day_raw_full_keep_all_fisheries, paste0("S:/FISHEyE/data/landings_tracker/day_raw_full_keep_all_fisheries", Sys.Date(), ".RDS"))
# List of fisheries that are either non-existent or have such small landings that
# it is not interpretable

rmfisheries_CA <- c(
    'MIDWATER',
    'PUGET SOUND FISHERIES',
    'CATCHER PROCESSOR',
    'MOTHERSHIP',
    'WHITING')

rmfisheries_WA <- c('NON-WHITING GROUNDFISH IFQ',
    'ANCHOVY',
    'MARKET SQUID',
    'NEARSHORE GROUNDFISH',
    'OTHER COASTAL PELAGIC',
    'OTHER CRAB',
    'SARDINE',
    'CATCHER PROCESSOR',
    'MOTHERSHIP')

rmfisheries_OR <- c(
    'ANCHOVY',
    'OTHER COASTAL PELAGIC',
    'OTHER CRAB',
    'PUGET SOUND FISHERIES',
    'SARDINE',
    'CATCHER PROCESSOR',
    'MOTHERSHIP')

rmfisheries_all <- 'NON-WHITING GROUNDFISH NON-IFQ'
  
# Has species group-level, all groundfish combined, state-level, and all states combined -still at the date-vessel-dealer level
# Recodes States and Fishery names
day_raw_full <- day_raw_full_keep_all_fisheries %>%
  # remove state-fishery combos that don't have enough data to show
  subset(
      !(SPECIES_GROUP %in% rmfisheries_CA & AGENCY_CODE == 'C') &
      !(SPECIES_GROUP %in% rmfisheries_WA & AGENCY_CODE == 'W') &
      !(SPECIES_GROUP %in% rmfisheries_OR & AGENCY_CODE == 'O') &
      !SPECIES_GROUP %in% rmfisheries_all) %>%
  # remove time-based species combos
  subset(
    # remove whiting before season opener
    !(SPECIES_GROUP %in% c('WHITING','CATCHER PROCESSOR', 'MOTHERSHIP') & WEEKOFYEAR < 18) &
    # remove pre July tuna from OR/WA
    !(SPECIES_GROUP == 'TUNA' & AGENCY_CODE %in% c('O','W') & WEEKOFYEAR < 24))  %>%
  # remove the at-sea labelled CP/MS since we already have the All version
  filter(!State == 'At-sea') %>%
  select(-AGENCY_CODE, -SPECIES_GROUP, -LANDING_YEAR)

#saveRDS(day_raw_full, "day_raw_full.RDS")
saveRDS(day_raw_full, paste0("S:/FISHEyE/data/landings_tracker/day_raw_full", Sys.Date(), ".RDS"))
# raw prices
day_prices <- pivot_wider(day_raw_full, names_from = 'Metric', values_from = 'Value', values_fn = length) %>%
  mutate(Value = EXVESSEL_REVENUE/(ROUND_WEIGHT_MTONS*2204.62),
         Metric = 'price')

# vessel-month totals
month_raw <- group_by(day_raw_full, 
        Year, VESSEL_NUM, DEALER_NUM, Species, LANDING_MONTH, State, Metric) %>%
    summarize(Value = sum(Value), .groups = 'drop') %>%
    mutate(Interval = 'Monthly') %>%
    subset(!(Year == 2021 & LANDING_MONTH >= month_datpull_date)) %>%
    data.frame() %>%
    rename(Dates = LANDING_MONTH)

# vessel-week totals
week_raw <- group_by(day_raw_full, 
        Year, VESSEL_NUM, DEALER_NUM, Species, WEEKOFYEAR, State, Metric) %>%
    summarize(Value = sum(Value), .groups = 'drop') %>%
    mutate(Interval = 'Weekly') %>%
    # drop incomplete data
    subset(!(Year == 2021 & WEEKOFYEAR >= week_datpull_date)) %>%
  data.frame() %>%
    rename(Dates = WEEKOFYEAR)

month_week_raw <- rbind(week_raw, month_raw) %>%
    mutate(CONF = 'NOT_TREATED')

# run the confidentiality checks and suppress fields as necessary in the raw data

confidentiality <- confTreat(month_week_raw, c('Year','Species','Dates','State','Metric', 'Interval'),
    valvar = 'Value', confunit = c('VESSEL_NUM','DEALER_NUM'), whichtables = 'both')

conf_for_prices <- group_by(confidentiality$flag, Year, Species, Dates, State, Interval) %>%
  summarise(flag = ifelse(any(final == 'suppress'), 'suppress', unique(final)))

# save the treated data from confidentiality check
# aggregation: RAW
# conf: TREATED
# cum: NA
month_week_treated <- mutate(confidentiality$data, CONF = 'TREATED')

# Treat the prices

month_prices <- select(day_prices, LANDING_MONTH, State, Species, Year, Metric, Value) %>%
  rename(Dates = LANDING_MONTH) %>%
  mutate(Interval = 'Monthly')

week_prices <- select(day_prices, WEEKOFYEAR, State, Species, Year, Metric, Value) %>%
  rename(Dates = WEEKOFYEAR) %>%
  mutate(Interval = 'Weekly')

prices_not_treated <- bind_rows(month_prices, week_prices) %>%
  mutate(CONF = 'NOT_TREATED')

prices <- prices_not_treated %>%
  left_join(conf_for_prices) %>%
  mutate(Value = ifelse(flag == 'ok', Value, NA)) %>%
  select(-flag) %>%
  mutate(CONF = 'TREATED') %>%
  bind_rows(prices_not_treated)

# dataframe with both the treated and untreated data
# aggregation: RAW
# conf: BOTH
# cum: NA
month_week_both <- rbind(month_week_raw, month_week_treated) %>%
  pivot_wider(names_from = Metric, values_from = Value) %>%
  pivot_longer(cols = ROUND_WEIGHT_MTONS:EXVESSEL_REVENUE,
               names_to = 'Metric',
               values_to = 'Value')

# Data analysis ####

# Calculating Ns

# Ns for the data tables
littleNs_yearly <- filter(month_week_raw, !is.na(VESSEL_NUM) & !is.na(DEALER_NUM)) %>%
    group_by(Species, State, Year, Dates, Interval) %>%
    summarize(
        N_vss = length(unique(VESSEL_NUM)),
        N_buy = length(unique(DEALER_NUM)), .groups = 'drop')

littleNs_baseline <- group_by(littleNs_yearly, Species, State, Dates, Interval) %>%
    # Using the kayleigh method for determining cross-year confidentiality
    summarize(
        N_vss = sum(N_vss),
        N_buy = sum(N_buy), .groups = 'drop') %>%
    mutate(Year = 'Baseline')

littleNs <- bind_rows(littleNs_yearly, littleNs_baseline)

# Ns as Metrics
Nasasmetric_raw <- reshape2::melt(littleNs_yearly, c('Species', 'State', 'Year', 'Dates', 'Interval')) %>%
    mutate(Metric = ifelse(variable == 'N_vss', 'Number of vessels',
        'Number of buyers')) %>%
    select(-variable) %>%
    left_join(littleNs_yearly, by = c('Species', 'State', 'Year', 'Dates', 'Interval')) %>%
    rename(Value = value)

Nasasmetric <- rbind(
    data.frame(Nasasmetric_raw, CONF = 'NOT_TREATED'),
    data.frame(Nasasmetric_raw, CONF = 'TREATED'))

# Calculating mean rev/mt by species group, agency_code, and month
comp_dat_dt <- data.table(month_week_both)

# aggregation: SUMM
# conf: TREATED + UNTREATED
# cum: No

comp_dat_dt <- rbind(comp_dat_dt[, .(Value=sum(Value)), by=list(VESSEL_NUM, Species, State, Year, Dates, Metric, CONF, Interval)],
                     data.frame(prices), fill = TRUE)
# Calculating the averages (both mean and median)
summ_avg        <- comp_dat_dt[, .(
    Mean = mean(Value), 
    Median = median(Value), 
    Variance = sd(Value), 
    q25 = quantile(Value, prob =.25, type = 8, na.rm = T),
    q75 = quantile(Value, prob =.75, type = 8, na.rm = T)), 
    by=.(Species, State, Year, Dates, Metric, CONF, Interval)] %>%
    reshape2::melt(c('Species','State', 'Year', 'Dates', 'Metric','Variance','q25','q75', 'CONF', 'Interval')) %>%
    rename(Statistic = variable,
        Value = value) %>%
    left_join(littleNs_yearly) %>%
    data.frame()

# Calculating the the totals
# aggregation: SUMM
# conf: TREATED + UNTREATED
# cum: No
summ_tot <- filter(month_week_both) %>%
    group_by(Species, State, Year, Dates, Metric, CONF, Interval) %>%
    summarize(Value = sum(Value), .groups = 'drop') %>%
    reshape2::dcast(Species + State + Year + Dates + CONF + Interval ~ Metric, value.var = 'Value') %>%
    mutate(price = EXVESSEL_REVENUE/(ROUND_WEIGHT_MTONS*2204.62)) %>%
    reshape2::melt(c('Species','State', 'Year', 'Dates', 'CONF', 'Interval')) %>%
    rename(Value = value, Metric = variable) %>%
    left_join(littleNs_yearly)  %>%
    rbind(Nasasmetric) %>%
    mutate(Statistic = 'Total',
        q25 = NA_real_,
        q75 = NA_real_,
        Variance = NA_real_)

# Bind together the summarized dataframes (averages and totals) + remove some date/fishery combos for periods before fishery "began"
# This is the FULL ANNUAL SUMMARIZED DATA SET
# aggregation: SUMM
# conf: TREATED + UNTREATED
# cum: No
summ_yearly <- rbind(summ_avg, summ_tot) %>%
    reshape2::melt(id.vars =c('Species','State','Year','Dates','Interval', 'Metric', 'CONF','Statistic')) %>%
    reshape2::dcast(Species + State + Year + Dates + Interval + Metric + CONF + Statistic ~ variable, value.var = 'value') %>%
    data.frame() %>%
    mutate(Cumulative = 'N')

# Baseline (5 yr median) calculated using the untreated data ####
# aggregation: medians
# conf: UNTREATED
# cum: No
# We need to remove 2015/2016 disaster years from the calculation of 35% for crab
# aggregation: medians
# conf: UNTREATED
# cum: No
medians_raw <- filter(summ_yearly, CONF == 'NOT_TREATED' &
  # remove disaster crab years
  !(Year %in% c(2015, 2016) & grepl('Dungeness crab', Species)) & 
    # remove 2020/2021
    !(Year %in% c(2020, 2021))) %>%
    group_by(Species, State, Dates, Metric, Statistic, Interval, Cumulative) %>%
    summarize(Value = median(Value), .groups = 'drop') %>%
    left_join(littleNs_baseline, by = c('Species', 'State', 'Dates', 'Interval')) %>%
    rename(Year = Year) %>%
    data.frame()

# Cumulative medians
# aggregation: medians
# conf: UNTREATED
# cum: Yes
medians_cumul <- subset(medians_raw, Statistic== 'Total' & !is.na(Value), -Cumulative) %>%
  group_by(Species, State, Metric, Statistic, Interval, Year) %>%
  arrange(Dates) %>%
  mutate(Value = cumsum(Value),
    Cumulative = 'Y',
    CONF = 'NOT_TREATED')

# Medians - raw and cumulative
medians_not_conf <- bind_rows(medians_raw, medians_cumul)

# we use the Kayleigh method for multi-year confidentiality
# aggregation: medians
# conf: TREATED
# cum: Both
medians_conf <- mutate(medians_not_conf,
    Value = case_when(!Metric %in% c('Number of vessels', 'Number of buyers') &
            # Suppress when vessel or buyer 1 or 2.
            ((N_vss < 3 & N_vss != 0) | (N_buy < 3 & N_buy != 0)) ~ NA_real_, T ~ Value ),
    CONF = 'TREATED',
    q25 = NA_real_,
    q75 = NA_real_,
    Variance = NA_real_) %>%
  mutate(CONF = 'TREATED')

# we use the Kayleigh method for multi-year confidentiality
# aggregation: medians
# conf: Both
# cum: Both
medians_all <- bind_rows(medians_not_conf, medians_conf) 
  
# Add not treated to be used with cumsum; can't have NAs when calculating cumsum

# Calculating cumulative totals ##### 
conftable <- confidentiality$flags

annual_w_conf_flags <- left_join(month_week_raw, conftable, by = c('Year', 'Species', 'Dates', 'State', 'Metric', 'Interval')) %>%
  arrange(Dates)

# split the raw data into unique sets of year, species, state, metric, interval
annual_w_conf_flags_split <- split(annual_w_conf_flags, list(
  annual_w_conf_flags$Year,
  annual_w_conf_flags$Species,
  annual_w_conf_flags$State,
  annual_w_conf_flags$Metric,
  annual_w_conf_flags$Interval), drop = TRUE)

annual_cumul_prep_data <- cumul_prep_fn(annual_w_conf_flags_split, "annual-level cumulative confidentiality prep")

annual_cumul_prep_data_conf <- select(annual_cumul_prep_data, -final) %>%
  confTreat(c('Year','Species','csflag','State','Metric', 'Interval'),
           valvar = 'Value', confunit = c('VESSEL_NUM','DEALER_NUM'), whichtables = 'datatable', inclorig = T) 


# aggregation: SUMM
# conf: TREATED
# cum: Yes
summ_yearly_cum <- mutate(annual_cumul_prep_data_conf,
  csflag = ifelse(csflag == 'clear', Dates, csflag)) %>%
  group_by(Year, Species, State, Metric, Interval, csflag) %>%
  # recalculate with the "preaccumulation" data points
  # Ashley note - I don't know what "preaccumulation" means...
  # It is at this step that we lose some of the dates because it seems like we are grouping by csflag
  # so for instance (Anchovy, Weight, Monthly, 2020, All) - dates 7 and 8 are both f3 so we lose 7.
  # I think this is a way to show more data? 
  # Erin can we add some more documentation/notes here. Its quite a learning curve to jump into this 
  # section of the code.
  summarise(
    Dates = max(Dates),
    Value = sum(Value),
    Valueorig = sum(Valueorig),
    N_vss = length(unique(VESSEL_NUM)),
    N_buy = length(unique(DEALER_NUM)), .groups = 'drop')  %>%
  group_by(Year, Species, State, Metric, Interval) %>%
  arrange(Dates) %>%
  # Calculate the cumulative totals
  mutate(cum_not_conf = cumsum(Valueorig)) %>%
  # Supress the cumulative totals based on the revised system
  mutate(Value = ifelse(is.na(Value), NA, cum_not_conf)) %>%
  select(-Valueorig, -cum_not_conf, -csflag) %>%
  mutate(
    Statistic = 'Total', 
    CONF = 'TREATED', 
    Variance = NA_real_, 
    q25 = NA_real_,
    q75 = NA_real_,
    Cumulative = 'Y')

# aggregation: SUMM
# conf: TREATED
# cum: Both
summ_all <- bind_rows(summ_yearly_cum, filter(summ_yearly, CONF == 'TREATED')) %>%
  bind_rows(medians_conf)

# sets up all combos of interval/date
date_matrix <- rbind(
  data.frame(Dates = 1:12, Interval = 'Monthly'),
  data.frame(Dates = 1:52, Interval = 'Weekly')
)

# pulls all of the state-year-species combos - if a species-year-state combo isn't in the data, it won't be populated with zeroes
sp_matrix <- distinct(summ_all, Year, State, Species)

# metric/state matrix
metric_matrix <- distinct(summ_all, Statistic, Metric, Cumulative)

full_matrix <- merge(date_matrix, sp_matrix) %>%
  merge(metric_matrix)

# Adding 0 for combos where there is no data; except for the cumulative data, then we add NA #####
# the conf_helper lets me identify which Value fields are NA because of confidentiality versus missing from the original data set
# aggregation: SUMM + medians
# conf: TREATED + UNTREATED
# cum: Both
# with zeroes
all_combos <- mutate(summ_all, conf_helper = 'data') %>%
  right_join(full_matrix) %>%
    subset(
      !(Interval == 'Monthly' & Dates >= month_datpull_date & Year == 2021) &
      !(Interval == 'Weekly'  & Dates >= week_datpull_date  & Year == 2021)) %>%
  # If the combo wasn't in the summ_all data set and Value is populated, set the value to zero (indicates that there were no landings found in the fish tickets for that combo)
  mutate(Value = case_when(is.na(conf_helper) & is.na(Value) & Cumulative != 'Y' ~ 0, 
                           is.na(conf_helper) & is.na(Value) & Cumulative == 'Y' ~ NA_real_,
                           T ~ Value)) %>%
  mutate(CONF = ifelse(is.na(conf_helper) & is.na(CONF), 'TREATED', CONF)) %>%
  select(-conf_helper)


# Calculating different filters###############
# 1) 2020 change. Compares 2020 value to the baseline ######
# baseline comparison
prep2020 <- filter(summ_yearly, 
    # pull the untreated values
      CONF == 'NOT_TREATED' &
      Metric == 'EXVESSEL_REVENUE' & 
      Statistic == 'Total' &
      Year %in% c('2020','2021') &
      Interval == 'Weekly') %>%
    group_by(Species, State) %>%
    mutate(cumREV_2020 = cumsum(Value),
        rm = case_when(State == 'All' & Species %in% c('Whiting: Catcher processor', 'Whiting: Mothership') &
                Dates > week(completeness_cutoff) ~ 1,
            State %in% c('California', 'Oregon', 'At-sea') & 
                Dates > week(completeness_cutoff) ~ 1,
            State %in% c('Washington', 'All') & 
                Dates > week(wk4_completeness) ~ 1,
            T ~ 0)) %>%
    filter(rm != 1) %>%
    ungroup()

cutoff_2020 <- prep2020 %>%
    group_by(Species, State) %>%
    summarize(Dates = max(Dates), .groups = 'drop')

only_2020 <- prep2020 %>%
    group_by(Species, State) %>%
    summarize(cumREV_2020 = max(cumREV_2020), .groups = 'drop')

baseline <- filter(summ_yearly, 
    # take care of crab disaster
    !(Year %in% c(2015, 2016) & grepl('Dungeness crab', Species)) &
        # not calculating for sardine because all years were disaster years
        Species != 'Sardine'    &
        # pull the untreated values
        CONF == 'NOT_TREATED' &
        Metric == 'EXVESSEL_REVENUE' & 
        Statistic == 'Total' &
        !Year %in% c('2020','2021') &
        Interval == 'Weekly' &
        !is.na(Metric)) %>%
    group_by(Species, State, Year) %>%
    mutate(cumREV = cumsum(Value)) %>%
    right_join(cutoff_2020) %>%
    group_by(Species, State) %>%
    summarize(cumREV_hist = median(cumREV), .groups = 'drop')%>%
    subset(!is.na(Species))

baseline_2020 <- left_join(only_2020, baseline) %>%
    mutate(percchange1 = (cumREV_2020-cumREV_hist)/cumREV_hist*100) %>%
    mutate(percdiff = percdiff(cumREV_hist, cumREV_2020)) %>%
    select(-cumREV_2020, -cumREV_hist) %>%
    data.table()

# 2) proportion within state ####
sharewithinstate <- subset(day_raw_full,
    Metric == 'EXVESSEL_REVENUE' & 
        Year %in% 2015:2019) %>%
    group_by(State, Species) %>%
    summarize(Value = sum(Value, na.rm = T), .groups = 'drop') %>%
    group_by(State) %>%
    mutate(state_prop1 = (Value/sum(Value, na.rm = T))*100) %>%
    select(-Value)
# 3) Share by month ######
sharewithinmonth <- subset(day_raw_full,
    Metric == 'EXVESSEL_REVENUE' & 
        Year %in% 2015:2019) %>%
    group_by(State, Species, LANDING_MONTH) %>%
    summarize(Value = sum(Value, na.rm = T), .groups = 'drop') %>%
    group_by(State, Species) %>%
    mutate(month_prop = (Value/sum(Value, na.rm = T))*100) %>%
    mutate(select_month = factor(month.abb[LANDING_MONTH], levels = month.abb)) %>%
    select(-LANDING_MONTH, -Value)

# All filters ####
addlfilters <- full_join(sharewithinstate, sharewithinmonth) %>%
    full_join(baseline_2020) %>%
    ungroup() %>%
    mutate(Species = as.factor(Species),
           State = as.factor(State),
        month_prop = case_when(is.na(month_prop) ~ NA_character_,
            month_prop <= 5 ~ '0-5%',
            month_prop > 5 & month_prop <= 10 ~ '5.1-10%',
            month_prop > 10 & month_prop <= 15 ~ '10.1-15%',
            month_prop > 15 & month_prop <= 20 ~ '15.1-20%',
            month_prop > 20 ~ '> 20%',
            T ~ 'help'),
        percchange = case_when(is.na(percchange1) ~ 'Cannot be calculated',
            percchange1 <= -35 ~ '\u2265 35% decrease', #\u2265 = greater than or equal to
            percchange1 > -35 & percchange1 <= 0 ~ '< 35% decrease',
            percchange1 > 0 & percchange1 <= 35 ~ '< 35% increase',
            percchange1 > 35 ~ '\u2265 35% increase', #\u2265 = greater than or equal to
            T ~ 'help'),
        state_prop = case_when(is.na(state_prop1) ~ NA_character_,
            state_prop1 <= 5 ~ '0-5%',
            state_prop1 > 5 & state_prop1 <= 10 ~ '5.1-10%',
            state_prop1 > 10 ~ '> 10%',
            T ~ 'help')
    ) %>%
    data.frame()

saveRDS(addlfilters, "addlfilters.RDS")
#write.fst(addlfilters, "addlfilters.fst")

# Apply state level suppression to all state summaries (i.e. if W is suppressed then All - (C+O) = W so need to suppress All) #####
# Do not apply to number of vessels/number of buyers
conf_state <- filter(all_combos, State != 'All' & !Metric %in% c('Number of buyers', 'Number of vessels')) %>%
    group_by(Year, Metric, Statistic, Dates, Interval, Species, Cumulative) %>%
    mutate(N_vss = case_when(is.na(N_vss) ~ 0,
        T ~ as.numeric(N_vss)),
        N_buy = case_when(is.na(N_buy) ~ 0,
            T ~ as.numeric(N_buy)),
        cases = case_when((N_vss < 3 & N_vss != 0 & !is.na(N_vss)) |
                (N_buy < 3 & N_buy != 0 & !is.na(N_buy)) ~ 1,
            T ~ 0)) %>%
    summarize(cases = sum(cases), .groups = 'drop') %>%
    mutate(State = 'All',
        conf_state = case_when(Species == 'Whiting: Shorebased' & State == 'All' & Year %in% c(2020, 2021) ~ 0,
            cases == 1 ~ 1,
            T ~ 0)) %>% 
    select(-cases)

# Confidentiality at the additive species level. The only one is All non-whiting groundfish ####
# Same logic applies as for states, except if more than one sub-categories are suppressed then do not need to suppress 
# the All category 

conf_species <- filter(all_combos, grepl('Non-whiting groundfish', Species) & 
                         !Metric %in% c('Number of buyers', 'Number of vessels')) %>%
    group_by(Year, Metric, Statistic, Dates, Interval, State, Cumulative) %>%
    mutate(N_vss = case_when(is.na(N_vss) ~ 0, T ~ as.numeric(N_vss)),
        N_buy = case_when(is.na(N_buy) ~ 0, T ~ as.numeric(N_buy)),
        cases = case_when((N_vss < 3 & N_vss != 0 & !is.na(N_vss)) |
                (N_buy < 3 & N_buy != 0 & !is.na(N_buy)) ~ 1,
            T ~ 0)) %>%
    summarize(cases = sum(cases), .groups = 'drop') %>%
    mutate(Species = 'All non-whiting groundfish',
        conf_species = case_when(cases == 1 ~ 1,
            T ~ 0)) %>% 
    select(-cases)

# Adding confidentiality checks for all states summaries
data_final <- full_join(conf_state, conf_species) %>%
    full_join(all_combos) %>%
    mutate(
        conf_state = case_when(is.na(conf_state) ~ 0, T ~ conf_state),
        conf_species = case_when(is.na(conf_species) ~ 0, T ~ conf_species), 
        Value    = ifelse(conf_state == 1 | conf_species == 1, NA_real_, Value),
        Variance = ifelse(conf_state == 1 | conf_species == 1, NA_real_, Variance),
        q25      = ifelse(conf_state == 1 | conf_species == 1, NA_real_, q25),
        q75      = ifelse(conf_state == 1 | conf_species == 1, NA_real_, q75),
        # When we do the all combos merge if data is missing it shows up as NA.
        N_vss = case_when(is.na(N_vss) & Year != 'Baseline' & Cumulative != 'Y' ~ 0,
            T ~ as.numeric(N_vss)),
        N_buy = case_when(is.na(N_buy) & Year != 'Baseline' & Cumulative != 'Y' ~ 0,
            T ~ as.numeric(N_buy)),
        Value = case_when(N_vss == 0 & N_buy == 0 ~ 0,
            T ~ Value)) %>%
    data.frame() %>%
  # remove revenue and prices for MS/CP
  subset(!(Species %in% c('Whiting: Catcher processor', 'Whiting: Mothership') & Metric %in% c('EXVESSEL_REVENUE', 'price')))

# Apply additive week/month confidentiality #####
# Rule = if only one week in month is suppressed then choose another month to suppress
# Chose by min(rev)

#Filter by weekly and treated because we only need to apply to weekly and the treated data
comp_dat_wk_conf <- data_final %>%
    filter(Interval == 'Weekly' & Cumulative == 'N' & Statistic == 'Total' &
            Metric == 'EXVESSEL_REVENUE') %>%
    # convert landing week to 2-digit character field
    mutate(Date2 = case_when( Dates < 10 ~ paste0('0', Dates), T ~ as.character(Dates)),
        # add arbitrary year for baseline
        LANDING_YEAR2 = case_when(Year == 'Baseline' ~ '2017',  T ~ Year),
        date_string   = case_when(
            Dates <= 1   ~    paste0(LANDING_YEAR2, '/01/Mon'),
            Dates > 1    ~ paste(LANDING_YEAR2, Date2, 'Mon', sep = "/")),
        first_day_of_week = as.Date(ymd(lubridate::parse_date_time(date_string, 'Y/W/a'))
        ),
        MONTH = month(first_day_of_week)
    ) %>%
    group_by(Species, State, Year, MONTH, Metric, Statistic) %>%
    # count the number of weeks in a month that are suppressed
    mutate(N_supp = sum(is.na(Value))) %>%
    # select the months that have one week suppressed; these are the ones that need additional conf
    filter(N_supp == 1) %>%
    ungroup() %>%
    # select needed columns (doing this just to simplify the logic)
    select(Species, State, Year, Dates, Interval, N_supp, Value, MONTH)

# This data frame will contain the combinations that should be suppressed
# and then which additional week to suppress by min total rev
comp_dat_wk_supp <- 
    # comp_dat_wk_conf is all of the MONTH-week-etc sets that need one more week suppressed
    # first we only keep the non-NA values
    filter(comp_dat_wk_conf, !is.na(Value)) %>%
    # then we find the "best" week in that combo to suppress (minimum of the remaining weeks)
    group_by(Species, State, Year, MONTH) %>%
    # This means select the min revenue value in the group
    top_n(-1, Value) %>%
    # If there is a tie we need to select one
    distinct(MONTH, .keep_all = T) %>%
    ungroup() %>%
    select(Species, State, Year, Dates, Interval, N_supp)

# Bind with the final dataframe and suppress values for those identified above.
almost_last_step <- full_join(data_final, comp_dat_wk_supp) %>%
    mutate(
        N_supp   = ifelse(is.na(N_supp),0,N_supp),
        Value    = case_when(N_supp == 1 ~ NA_real_, T ~ Value),
        Variance = case_when(N_supp == 1 ~ NA_real_, T ~ Variance),
        q25      = case_when(N_supp == 1 ~ NA_real_, T ~ q25),
        q75      = case_when(N_supp == 1 ~ NA_real_, T ~ q75)) %>%
    select(-N_supp)

# Final formatting ####
app_data_fmt <-    almost_last_step %>%
  ungroup() %>%
  mutate(Metric = case_when(Metric == 'EXVESSEL_REVENUE' ~ 'Exvessel revenue',
                            Metric == 'ROUND_WEIGHT_MTONS' ~ 'Landed weight (mt)',
                            Metric == 'price' ~ 'Price (per lb)',
                            T ~ as.character(Metric)),
         Species = as.factor(Species),
         State = as.factor(State),
         Type = ifelse(Year %in% 2015:2019, '2015-2019',
                       Year)) %>%
  group_by(Metric, Statistic, Cumulative, Interval) %>%
  mutate(unit = ifelse(all(is.na(Value)), '',
                       ifelse(max(Value, na.rm = T) < 1e3, '',
                              ifelse(max(Value, na.rm = T) < 1e6, 'thousands',
                                     ifelse(max(Value, na.rm = T) < 1e9, 'millions',
                                            ifelse(max(Value, na.rm = T) < 1e12, 'billions',
                                                   'help'))))),
         Variance = case_when(!(Year %in% c(2020, 2021)) ~ NA_real_, T ~ Variance),
         q25 = case_when(!(Year %in% c(2020, 2021)) ~ NA_real_,  T ~ q25),
         q75 = case_when(!(Year %in% c(2020, 2021)) ~ NA_real_, T ~ q75)
  )    %>%
  ungroup() %>%
  mutate(
    Year = as.factor(Year),
    Value = case_when(
      unit == '' ~ Value,
      unit == 'thousands' ~ Value/1e3,
      unit == 'millions' ~ Value/1e6,
      unit == 'billions' ~ Value/1e9,
      T ~ -999),
    Variance = case_when(
      unit == '' ~ Variance,
      unit == 'thousands' ~ Variance/1e3,
      unit == 'millions' ~ Variance/1e6,
      unit == 'billions' ~ Variance/1e9,
      T ~ -999),
    q25 = case_when(
      unit == '' ~ q25,
      unit == 'thousands' ~ q25/1e3,
      unit == 'millions' ~    q25/1e6,
      unit == 'billions' ~    q25/1e9,
      T ~ -999),
    q75 = case_when(
      unit == '' ~ q75,
      unit == 'thousands' ~ q75/1e3,
      unit == 'millions' ~    q75/1e6,
      unit == 'billions' ~    q75/1e9,
      T ~ -999),
    ylab = case_when(Metric %in% c('Exvessel revenue', 'Price (per lb)') ~
                       paste0(State, ": ", Species, "\n(", unit, " 2021$)"),
                     Metric == 'Landed weight (mt)' ~
                       paste0(State, ": ", Species, "\n(", unit, " mt)"),
                     Metric == 'Number of vessels' ~
                       paste0(State, ": ", Species, "\n(", unit, ")"), 
                     T ~ paste(State, ": ", Species)),
    # ylab modifications
    ylab = gsub('()', '', ylab, fixed = T),
    upper = case_when(Statistic == 'Mean' ~ Value + Variance,
                      Statistic == 'Median' ~ q75,
                      Statistic == 'Total' ~ Value),
    lower = case_when(Statistic == 'Mean' ~ Value - Variance,
                      Statistic == 'Median' ~ q25,
                      Statistic == 'Total' ~ Value),
    Type = ifelse(Type == 'Baseline', '2015-2019 Median', Type),
    Type = factor(Type, levels = c('2015-2019', '2015-2019 Median', '2020', '2021'))) 

app_data_fmt_dates <- app_data_fmt %>%
  # Need to add zero in front of month and landing week to parse the date together
  mutate(Dates_as_char = case_when(Dates < 10 ~ paste0('0', Dates), T ~ as.character(Dates))) %>%  
  # fill in a year for baseline
  mutate(baseline_as_year = ifelse(Year == 'Baseline', '2017', as.character(Year))) %>%
  # date with the actual year for the data table
  mutate(
    # here we convert dates (week/month) to date character strings then format as date for the table (i.e., with correct year)
    pre_date = case_when(
      Interval == 'Weekly' & Dates < 2 ~ as.Date(paste0(baseline_as_year, '/01/01')),
      Interval == 'Weekly' & Dates > 1 ~ as.Date(paste(baseline_as_year, Dates_as_char, '1', sep = "/"), '%Y/%W/%w'),
      Interval == 'Monthly' ~ as.Date(paste0(baseline_as_year, '/', Dates_as_char, '/01'))),
    # the only difference here is that we change year to 2001 for plotting 
    Date_plot = case_when(
      Interval == 'Weekly' & Dates < 2 ~ as.Date('2001-01-01'),
      Interval == 'Weekly' & Dates > 1 ~ as.Date(paste(2001, Dates_as_char, '1', sep="/"), '%Y/%W/%w'),
      Interval == 'Monthly' ~ as.Date(paste0('2001', '/', Dates_as_char, '/01')))) %>%
  # # apply completeness/uncertainty logic. best understanding is that WA is 4 week lag, apply different logic for WA
   mutate(
    complete = case_when(
      State == 'Washington' & Interval == 'Weekly' &
        pre_date >= wk4_completeness ~ "uncertain",
      # I don't think we need this anymore
      # State == 'Washington' & Statistic == 'Total' & Interval == 'Monthly' & Year %in% c(2020) &
      #    Dates > wk4_month ~ "uncertain",
      Interval == 'Weekly' & pre_date >= completeness_cutoff ~ "uncertain",
      # Interval == 'Monthly' & Year %in% c(2020, 2021) & Dates > month_cutoff ~ "uncertain",
      T ~ "complete"),
    no_pts = case_when(Type == '2015-2019' ~ 1,
      Cumulative == 'Y' &
        Interval == 'Weekly' & Type == 'Baseline' ~ 1,
      T ~ 0),
    # remove data they we don't want
    # Only want cumulative data when metric == exvessel revenue or weight
    rm_data = case_when(
      Cumulative == 'Y' &
        !Metric %in% c('Exvessel revenue', 'Landed weight (mt)') ~ 1,
      Statistic != 'Total' &
        Metric %in% c('Number of vessels', 'Number of buyers') ~ 1,
      Species == 'Whiting: Shorebased' &
        State != 'All' & Year %in% c(2020, 2021) ~ 1,
      # we suppress historical data for whiting shorebased on the All figure. it is confusing to leave the 
      # data in the table so I am removing it here.
      # Species == 'Whiting: Shorebased' &
      #   State == 'All' & !Year %in% c(2020, 2021) ~ 1,
      Species %in% c('Whiting: Catcher processor', 'Whiting: Mothership') & Metric %in% c('Exvessel Revenue', 'Price (per lb)') ~ 1,
      T ~ 0
    )
  ) %>%
  filter(rm_data != 1) %>%
  select(-rm_data) %>%
  data.frame()
return(app_data_fmt_dates)
# Sometimes I use the line below for testing that something works in app. Good practice is to go through the dataprep code though
#saveRDS(app_data_fmt_dates, "comp_dat_covidapp.RDS")
}


